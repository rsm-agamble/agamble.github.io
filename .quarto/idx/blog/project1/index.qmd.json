{"title":"A Replication of Karlan and List (2007)","markdown":{"headingText":"HW 1","containsRefs":false,"markdown":"\n---\ntitle: \"A Replication of Karlan and List (2007)\"\nauthor: \"Alexa Gamble\"\ndate: 04/17/2025\ncallout-appearance: minimal # this hides the blue \"i\" icon on .callout-notes\n---\n\n\n## Introduction\n\nDean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).\n\nThis large-scale natural field experiment was designed to explore whether **price incentives**, framed through **matching gifts**, influence charitable giving behavior. In the treatment group, donors were told that a “concerned fellow member” would match their donation at varying rates: 1:1, 2:1, or 3:1. Each donor was randomly assigned to one of these match ratios, to a specific suggested donation amount, and to a maximum gift match cap. In contrast, the control group received a standard appeal letter without any mention of a match.\n\nThe study investigates how these price frames affect both the **likelihood of giving** and the **amount donated**. Importantly, the match offers were real and implemented through a conditional agreement with anonymous donors. The paper contributes to the economic literature by testing whether traditional assumptions about donor price sensitivity hold in real-world charitable giving, an area long theorized but rarely tested at this scale and with this level of experimental control.\n\nThis report replicates and extends aspects of Karlan and List’s analysis using their public dataset. Specifically, I analyze whether matched donations lead to higher response rates, whether larger match ratios produce stronger effects, and whether the treatment influenced the size of contributions. I also use simulation to illustrate key statistical concepts such as the Law of Large Numbers and the Central Limit Theorem, which underpin the validity of the experimental estimates.\n\nThis project seeks to replicate their results.\n\n\n## Data\n\n### Description\n```{python} \nimport pandas as pd\nimport numpy as np\ndf_k = pd.read_stata(\"/home/jovyan/Desktop/MGTA 495 - Marketing Analytics/karlan_list_2007.dta\")\ndf_k\n```\n\nThe dataset consists of **50,083 observations** and **51 variables**, and appears to originate from a field experiment or observational study, likely related to donation behavior or outreach strategies. Each row represents an individual unit (e.g., a household or donor), and the dataset includes both treatment assignments and a range of covariates.\n\n#### Key Variables\n\n- **`treatment`**, **`control`**: Binary indicators denoting experimental group assignment. A value of `1` in `treatment` indicates the subject received the treatment condition, while `1` in `control` indicates assignment to the control group. These two variables are mutually exclusive.\n- **`ratio`**, **`ratio2`**, **`ratio3`**: Variables reflecting matching incentives (e.g., 1:1, 2:1 matches) provided during the intervention. These are likely categorical or indicator variables showing the ratio level applied.\n- **`size`**, **`size25`**, **`size50`**, **`size100`**, **`sizeno`**: Donation ask size variables. The `size` column includes textual representations of the suggested donation amount (e.g., `\"$100,000\"`), while the other columns serve as binary indicators for specific size categories.\n\n#### Demographic & Contextual Variables\n\n- **`redcty`**, **`bluecty`**: Indicators of political affiliation or voting patterns in the subject’s county or city.\n- **`pwhite`**, **`pblack`**: Proportion of white and Black residents in the geographic area.\n- **`page18_39`**: Proportion of the population between ages 18 and 39.\n- **`ave_hh_sz`**: Average household size.\n- **`median_hhincome`**: Median household income in the area.\n- **`powner`**: Proportion of homeowners.\n- **`psch_atlstba`**: Proportion of the population with at least a bachelor's degree.\n- **`pop_propurban`**: Proportion of the population living in urban areas.\n\n#### Missing Data\n\nSeveral rows contain missing values (`NaN`), especially in demographic variables like `pwhite`, `pblack`, and `median_hhincome`. These may result from incomplete geographic data or limitations in census coverage.\n\n\n\n:::: {.callout-note collapse=\"true\"}\n### Variable Definitions\n\n| Variable             | Description                                                         |\n|----------------------|---------------------------------------------------------------------|\n| `treatment`          | Treatment                                                           |\n| `control`            | Control                                                             |\n| `ratio`              | Match ratio                                                         |\n| `ratio2`             | 2:1 match ratio                                                     |\n| `ratio3`             | 3:1 match ratio                                                     |\n| `size`               | Match threshold                                                     |\n| `size25`             | \\$25,000 match threshold                                            |\n| `size50`             | \\$50,000 match threshold                                            |\n| `size100`            | \\$100,000 match threshold                                           |\n| `sizeno`             | Unstated match threshold                                            |\n| `ask`                | Suggested donation amount                                           |\n| `askd1`              | Suggested donation was highest previous contribution                |\n| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |\n| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |\n| `ask1`               | Highest previous contribution (for suggestion)                      |\n| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |\n| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |\n| `amount`             | Dollars given                                                       |\n| `gave`               | Gave anything                                                       |\n| `amountchange`       | Change in amount given                                              |\n| `hpa`                | Highest previous contribution                                       |\n| `ltmedmra`           | Small prior donor: last gift was less than median \\$35              |\n| `freq`               | Number of prior donations                                           |\n| `years`              | Number of years since initial donation                              |\n| `year5`              | At least 5 years since initial donation                             |\n| `mrm2`               | Number of months since last donation                                |\n| `dormant`            | Already donated in 2005                                             |\n| `female`             | Female                                                              |\n| `couple`             | Couple                                                              |\n| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |\n| `nonlit`             | Nonlitigation                                                       |\n| `cases`              | Court cases from state in 2004-5 in which organization was involved |\n| `statecnt`           | Percent of sample from state                                        |\n| `stateresponse`      | Proportion of sample from the state who gave                        |\n| `stateresponset`     | Proportion of treated sample from the state who gave                |\n| `stateresponsec`     | Proportion of control sample from the state who gave                |\n| `stateresponsetminc` | stateresponset - stateresponsec                                     |\n| `perbush`            | State vote share for Bush                                           |\n| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |\n| `red0`               | Red state                                                           |\n| `blue0`              | Blue state                                                          |\n| `redcty`             | Red county                                                          |\n| `bluecty`            | Blue county                                                         |\n| `pwhite`             | Proportion white within zip code                                    |\n| `pblack`             | Proportion black within zip code                                    |\n| `page18_39`          | Proportion age 18-39 within zip code                                |\n| `ave_hh_sz`          | Average household size within zip code                              |\n| `median_hhincome`    | Median household income within zip code                             |\n| `powner`             | Proportion house owner within zip code                              |\n| `psch_atlstba`       | Proportion who finished college within zip code                     |\n| `pop_propurban`      | Proportion of population urban within zip code                      |\n\n::::\n\n\n### Balance Test \n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nTo assess whether the random assignment mechanism was successful, I conduct balance tests on three baseline variables that are not influenced by treatment:\n\n- `mrm2`: months since last donation  \n- `pwhite`: proportion of white residents in the donor’s area  \n- `ave_hh_sz`: average household size\n\nFor each variable, I apply both a **manual t-test** and a **linear regression** to compare treatment and control groups. These methods should yield consistent results, since both estimate the same underlying difference in means.\n\n```{python}\nimport statsmodels.formula.api as smf\nfrom scipy import stats\n\n# Function to compute manual t-test and regression for a given variable\ndef balance_test(df, variable, treatment_col=\"treatment\"):\n    df_clean = df.dropna(subset=[variable, treatment_col])\n    treat = df_clean[df_clean[treatment_col] == 1][variable]\n    control = df_clean[df_clean[treatment_col] == 0][variable]\n\n    # Manual t-test\n    mean_treat = treat.mean()\n    mean_control = control.mean()\n    var_treat = treat.var(ddof=1)\n    var_control = control.var(ddof=1)\n    n_treat = len(treat)\n    n_control = len(control)\n    se = np.sqrt(var_treat/n_treat + var_control/n_control)\n    t_stat = (mean_treat - mean_control) / se\n\n    # Welch's degrees of freedom\n    df_num = (var_treat/n_treat + var_control/n_control)**2\n    df_denom = ((var_treat/n_treat)**2 / (n_treat - 1)) + ((var_control/n_control)**2 / (n_control - 1))\n    df_eff = df_num / df_denom\n\n    print(f\"\\n=== Balance Test: {variable} ===\")\n    print(f\"Manual t-test: t = {t_stat:.4f}, df ≈ {df_eff:.2f}\")\n\n    # Linear regression\n    formula = f\"{variable} ~ {treatment_col}\"\n    model = smf.ols(formula, data=df_clean).fit()\n    coef = model.params[treatment_col]\n    pval = model.pvalues[treatment_col]\n    print(f\"Regression coefficient on treatment: {coef:.4f}, p = {pval:.4f}\")\n    return model.summary()\n\nbalance_test(df_k, \"mrm2\")\nbalance_test(df_k, \"pwhite\")\nbalance_test(df_k, \"ave_hh_sz\")\n```\n\n\n#### `mrm2` (Months Since Last Donation)\n\n- **Manual t-test**:\n  - t-statistic: **0.1195**, degrees of freedom ≈ 33,394, p = **0.905**\n  - Not statistically significant\n\n- **Regression (`mrm2 ~ treatment`)**:\n  - Coefficient on `treatment`: **0.0137**\n  - p-value: **0.905**\n\nInterpretation: There is no statistically significant difference in prior giving recency between the groups, indicating balance.\n\n---\n\n#### `pwhite` (Proportion White)\n\n- **Manual t-test**:\n  - t-statistic: **–0.5590**, degrees of freedom ≈ 31,876, p = **0.5753**\n  - Not statistically significant\n\n- **Regression (`pwhite ~ treatment`)**:\n  - Coefficient on `treatment`: **–0.0009**\n  - p-value: **0.5753**\n\nInterpretation: Racial composition across treatment and control groups is nearly identical, with no meaningful difference detected.\n\n---\n\n#### `ave_hh_sz` (Average Household Size)\n\n- **Manual t-test**:\n  - t-statistic: **0.8234**, degrees of freedom ≈ 31,960, p = **0.4108**\n  - Not statistically significant\n\n- **Regression (`ave_hh_sz ~ treatment`)**:\n  - Coefficient on `treatment`: **0.0030**\n  - p-value: **0.4108**\n\nInterpretation: Household size is well balanced between the groups, with the regression confirming no significant difference.\n\n### Comments\n\nThe results from all three variables show no statistically significant differences between the treatment and control groups. This supports the integrity of the randomization process and aligns with Table 1 in Karlan and List (2007), which was included in the original paper for the same purpose.\n\nBy demonstrating that key baseline characteristics are similar across groups, we can be more confident that any observed differences in outcome variables can be attributed to the treatment itself rather than to underlying differences in the populations.\n\nThe balance tests confirm that random assignment was successfully implemented in the experiment.\n\n## Experimental Results\n\n### Charitable Contribution Made\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation. \n\n```{python}\nimport matplotlib.pyplot as plt\n\ndf_k['gave'] = (df_k['amount'] > 0).astype(int)\n\nresponse_rates = df_k.groupby('treatment')['gave'].mean()\nlabels = ['Control', 'Treatment']\n\nplt.figure(figsize=(6, 4))\nplt.bar(labels, response_rates, color=['gray', 'blue'])\nplt.ylabel('Proportion Donated')\nplt.title('Response Rate by Group')\nplt.ylim(0, 0.05) \nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()\n```\n\n\n```{python}\n\ndf_k['gave'] = (df_k['amount'] > 0).astype(int)\n\ngave_treat = df_k[df_k['treatment'] == 1]['gave']\ngave_control = df_k[df_k['treatment'] == 0]['gave']\n\n# Manual t-test (Welch's t-test)\nmean_treat = gave_treat.mean()\nmean_control = gave_control.mean()\nvar_treat = gave_treat.var(ddof=1)\nvar_control = gave_control.var(ddof=1)\nn_treat = len(gave_treat)\nn_control = len(gave_control)\n\nse = np.sqrt(var_treat/n_treat + var_control/n_control)\nt_stat = (mean_treat - mean_control) / se\n\ndf_num = (var_treat/n_treat + var_control/n_control)**2\ndf_denom = ((var_treat/n_treat)**2 / (n_treat - 1)) + ((var_control/n_control)**2 / (n_control - 1))\ndf_eff = df_num / df_denom\n\np_val = 2 * (1 - stats.t.cdf(abs(t_stat), df=df_eff))\n\nprint(f\"T-test result: t = {t_stat:.4f}, df ≈ {df_eff:.0f}, p = {p_val:.4f}\")\n\n# Linear regression: gave ~ treatment\nmodel = smf.ols(\"gave ~ treatment\", data=df_k).fit()\nprint(model.summary())\n```\n\n### Response Rate Analysis\n\nTo test whether offering a matching donation influenced charitable behavior, I examined the **response rate** — the proportion of individuals who made any donation — across treatment and control groups.\n\n#### Statistical Results\n\nUsing a **t-test**, I found a statistically significant difference in donation rates:\n\n- **t = 3.21**, degrees of freedom ≈ 36,577  \n- **p = 0.0013**\n\nI also ran a **bivariate linear regression**:\n\n- `gave ~ treatment`  \n- Coefficient on `treatment`: **0.0042**,  \n- Standard error: **0.0014**  \n- **p = 0.002**\n\nThis confirms that individuals in the treatment group were significantly more likely to donate than those in the control group.\n\n#### Context and Interpretation\n\nThe estimated treatment effect is about **0.42 percentage points** - small in absolute terms, but statistically meaningful. This suggests that **framing a donation opportunity with a matching offer** leads to an increased likelihood that someone contributes, even if the match amount or ratio isn't overwhelming.\n\nIn other words, **people are more responsive to the idea that their donation will be matched**, likely because it enhances their perceived impact or makes the opportunity feel more urgent or meaningful.\n\n#### Comparison to Table 2A\n\nThese results align closely with the findings reported in **Table 2A, Panel A** of Karlan and List (2007):\n\n- Reported control group response rate: **1.8%**  \n- Reported treatment group response rate: **2.2%**  \n- Difference: **0.004** (**0.4 percentage points**)\n\nThis nearly matches the **0.0042** effect size estimated in my regression. This agreement supports the accuracy of my replication and reinforces the study’s conclusion: **matching offers boost donation behavior in a statistically and behaviorally significant way**.\n\n```{python}\n\ndf_k['gave'] = (df_k['amount'] > 0).astype(int)\n\n# Probit regression\nprobit_model = smf.probit(\"gave ~ treatment\", data=df_k).fit()\nprint(probit_model.summary())\n```\n\n### Probit Regression: Replicating Table 3 Column (1)\n\nTo replicate Table 3 Column (1) from Karlan and List (2007), I ran a probit regression with the binary outcome variable `gave` (1 if a person donated, 0 otherwise), and the explanatory variable `treatment` (1 for treatment group, 0 for control).\n\nThe probit regression output was as follows:\n\n- Coefficient on `treatment`: **0.087**\n- Standard error: **0.028**\n- z-value: **3.11**\n- p-value: **0.002**\n\nThis result is statistically significant at the **1% level**, and the direction and significance **match the findings reported in Table 3 of the original paper**. While the numerical values differ slightly due to scale and model presentation, the key takeaway is consistent: **treatment increases the likelihood of making a donation**.\n\n#### Interpretation\n\nThe probit model confirms that **simply being told about a matching donation offer makes individuals more likely to give**, even after accounting for the non-linear nature of the donation decision. This suggests that small behavioral cues, like highlighting a match, can meaningfully impact real-world choices. My findings support the original authors' conclusion that match framing positively influences charitable behavior.\n\n\n### Differences between Match Rates\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n```{python}\n\ndf_k['gave'] = (df_k['amount'] > 0).astype(int)\n\ntreatments = df_k[df_k['treatment'] == 1]\n\n# Compare 1:1 vs 2:1\ngave_1 = treatments[treatments['ratio'] == 1]['gave']\ngave_2 = treatments[treatments['ratio'] == 2]['gave']\ntstat_12, pval_12 = stats.ttest_ind(gave_1, gave_2, equal_var=False)\n\n# Compare 1:1 vs 3:1\ngave_3 = treatments[treatments['ratio'] == 3]['gave']\ntstat_13, pval_13 = stats.ttest_ind(gave_1, gave_3, equal_var=False)\n\nprint(f\"1:1 vs 2:1 — t = {tstat_12:.4f}, p = {pval_12:.4f}\")\nprint(f\"1:1 vs 3:1 — t = {tstat_13:.4f}, p = {pval_13:.4f}\")\n```\n\n#### Interpretation\n\nTo evaluate whether **larger match ratios** (2:1 or 3:1) increase the likelihood of giving more than the standard 1:1 match, I conducted two separate t-tests on donation rates within the treatment group:\n\n- **1:1 vs 2:1** match ratio:  \n  - t = –0.965, p = 0.335\n- **1:1 vs 3:1** match ratio:  \n  - t = –1.015, p = 0.310\n\nIn both cases, the p-values are **well above the 0.05 threshold**, indicating **no statistically significant difference** in donation response rates between the 1:1 match and the higher match ratios.\n\nThese findings are consistent with the authors’ observation on **page 8** of the paper:  \n\n*\"Larger match ratios—$3:$1 and $2:$1—relative to smaller match ratios ($1:$1) have no additional impact.\"*\n\nMy results confirm that **increasing the match ratio does not meaningfully change behavior**. While one might expect that offering a 2:1 or 3:1 match would further incentivize donations, the evidence suggests that donors are **primarily influenced by the presence of a match**, rather than its size.\n\nThis aligns with the **\"figures suggest\"** comment in the paper, which points out that **neither the size of the match ratio nor the match threshold meaningfully affected giving behavior**, once the existence of a match was established.\n\nConclusion: A match offer matters, but bigger is not necessarily better. For fundraisers, this means that emphasizing the **existence** of a match may be more impactful than maximizing the match ratio.\n\n\n```{python}\n\ndf_ratios = df_k[(df_k['treatment'] == 1) & (df_k['ratio'].isin([1, 2, 3]))].copy()\ndf_ratios['gave'] = (df_ratios['amount'] > 0).astype(int)\n\ndf_ratios['ratio'] = pd.Categorical(df_ratios['ratio'], categories=[1, 2, 3])\n\nmodel = smf.ols(\"gave ~ C(ratio)\", data=df_ratios).fit()\nprint(model.summary())\n\n```\n\n### Regression: Effect of Match Ratio on Donation Likelihood\n\nTo assess whether larger matching ratios (2:1 or 3:1) lead to higher donation rates than a 1:1 match, I ran an OLS regression within the treatment group. The dependent variable `gave` indicates whether a donation was made, and the independent variable is the categorical match `ratio` (with 1:1 as the baseline).\n\n#### Results\n\n- **Intercept (1:1 match rate)**: 2.07% donation rate  \n- **2:1 match rate**: +0.19 percentage points (p = 0.338)  \n- **3:1 match rate**: +0.20 percentage points (p = 0.313)\n\nNone of the coefficients on the higher match ratios were statistically significant. The R-squared is essentially zero, meaning the model explains **none of the variation** in giving behavior based on match size alone.\n\n#### Interpretation\n\nThese findings are consistent with earlier results and the original study by Karlan and List (2007). While one might expect larger match ratios to increase giving, the data show that **donation likelihood does not significantly differ between 1:1, 2:1, and 3:1 matches**.\n\nThe presence of a match matters more than its size. Increasing the match ratio does **not** significantly increase the probability that someone donates.\n\nThis reinforces the practical takeaway: **simple match framing works**, and there may be diminishing behavioral returns to making the match larger.\n\n\n```{python}\n\n# 1. Calculate directly from the data\ndf_ratios = df_k[(df_k['treatment'] == 1) & (df_k['ratio'].isin([1, 2, 3]))].copy()\ndf_ratios['gave'] = (df_ratios['amount'] > 0).astype(int)\n\nresp_1 = df_ratios[df_ratios['ratio'] == 1]['gave'].mean()\nresp_2 = df_ratios[df_ratios['ratio'] == 2]['gave'].mean()\nresp_3 = df_ratios[df_ratios['ratio'] == 3]['gave'].mean()\n\n# Differences from raw data\ndiff_12_data = resp_2 - resp_1\ndiff_23_data = resp_3 - resp_2\n\n# 2. From fitted regression coefficients\ncoef_1 = 0.0207  \ncoef_2 = coef_1 + 0.0019 \ncoef_3 = coef_1 + 0.0020  \n\ndiff_12_model = coef_2 - coef_1\ndiff_23_model = coef_3 - coef_2\n\nprint(f\"Raw data differences:\")\nprint(f\"2:1 – 1:1 = {diff_12_data:.4f}\")\nprint(f\"3:1 – 2:1 = {diff_23_data:.4f}\\n\")\n\nprint(f\"Model-based differences (fitted values):\")\nprint(f\"2:1 – 1:1 = {diff_12_model:.4f}\")\nprint(f\"3:1 – 2:1 = {diff_23_model:.4f}\")\n```\n\n### Comparing Response Rates Across Match Ratios\n\nTo assess whether larger match ratios lead to higher donation rates, I compared the response rates between match levels using both raw data and fitted values from a regression model.\n\n#### 1. **Raw Data Differences**\n- **2:1 – 1:1**: 0.0019 (0.19 percentage points)\n- **3:1 – 2:1**: 0.0001 (0.01 percentage points)\n\n#### 2. **Model-Based Differences (from regression coefficients)**\n- **2:1 – 1:1**: 0.0019\n- **3:1 – 2:1**: 0.0001\n\nThe results from both approaches are nearly identical, reinforcing their reliability. The increase in response rate from 1:1 to 2:1 is **less than 0.2 percentage points**, and the difference from 2:1 to 3:1 is effectively zero.\n\n#### Interpretation\n\nThese findings provide strong evidence that **increasing the match ratio beyond 1:1 does not meaningfully impact donation behavior**. While the idea of a higher match may seem more generous or compelling, actual donor behavior appears largely indifferent to the size of the match.\n\nThe behavioral \"nudge\" comes from the **presence of a match offer**, not the **magnitude** of the match.\n\nThis aligns with the key insight of Karlan and List (2007): **“larger match ratios… have no additional impact.”**\n\n\n### Size of Charitable Contribution\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n```{python}\ndf = df_k.copy()\n\n# 1. T-test on donation amount\namount_treat = df[df['treatment'] == 1]['amount']\namount_control = df[df['treatment'] == 0]['amount']\nt_stat, p_val = stats.ttest_ind(amount_treat, amount_control, equal_var=False)\n\n# 2. Regression of amount on treatment\nmodel = smf.ols(\"amount ~ treatment\", data=df).fit()\n\nprint(f\"T-test result: t = {t_stat:.4f}, p = {p_val:.4f}\")\nprint(model.summary())\n```\n\n### Interpretation\n\nTo assess whether the matching donation offer affected not just the likelihood of giving, but also the **size of the contribution**, I conducted both a t-test and a linear regression of the donation amount on treatment status.\n\n#### T-test Result\n- **t = 1.92**\n- **p = 0.055**\n\nThis result is **marginally statistically significant** — just above the conventional 5% threshold. It suggests a potential difference in average donation amount between treatment and control groups.\n\n#### Regression Result\n- **Coefficient on treatment**: **$0.15**\n- **p = 0.063**\n\nThe regression indicates that individuals in the treatment group gave, on average, about **15 cents more** than those in the control group. This difference is also **marginally significant** and should be interpreted cautiously.\n\nThese results suggest that the **match offer may have a small effect on the size of donations**, not just the likelihood of giving — but this effect is **not robustly statistically significant**. In practical terms, most of the **impact of the match framing seems to come from getting more people to donate**, rather than increasing how much they give.\n\nFor fundraisers, this distinction matters: **matching appeals may increase participation**, but not necessarily the donation amount per person.\n\n\n```{python}\n\ndf_positive = df_k[df_k['amount'] > 0].copy()\n\nmodel_positive = smf.ols(\"amount ~ treatment\", data=df_positive).fit()\n\nprint(model_positive.summary())\n```\n\n### Conditional on Giving: Size of Donation\n\nTo explore how the treatment affected **donation size among those who gave**, I limited the data to respondents with a positive donation amount and regressed `amount` on `treatment`.\n\n#### Regression Results\n- **Intercept**: $45.54  \n- **Treatment effect**: –$1.67  \n- **p-value**: 0.561\n\nThis suggests that, among donors, those in the treatment group gave slightly **less** than those in the control group, by about **$1.67 on average**. However, this difference is **not statistically significant**, meaning we cannot rule out the possibility that the true difference is zero.\n\n#### Interpretation\n\nThese results suggest that while the **match offer may influence whether someone gives**, it does **not meaningfully affect the donation amount among those who already decided to give**.\n\n#### Causal Interpretation?\n\nIt's important to note that this estimate **does not have a causal interpretation**. While treatment assignment was randomized, we are now analyzing a **non-random subset**: people who chose to give.\n\nBecause giving is **influenced by the treatment**, conditioning on it introduces **selection bias**, the comparison may now be confounded by unobserved differences between donors in the treatment and control groups.\n\nIn short: **we can’t say the treatment caused donors to give less** — we’re just observing that **among givers**, the average gift was slightly lower in the treatment group.\n\nThe key takeaway remains: **matching increases participation**, but not necessarily contribution\n\n\n\n```{python}\n\ndonors = df_k[df_k['amount'] > 0].copy()\n\ndonors_treat = donors[donors['treatment'] == 1]\ndonors_control = donors[donors['treatment'] == 0]\n\nmean_treat = donors_treat['amount'].mean()\nmean_control = donors_control['amount'].mean()\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 5))\n\naxes[0].hist(donors_treat['amount'], bins=30, color='skyblue', edgecolor='black')\naxes[0].axvline(mean_treat, color='red', linestyle='--', label=f'Mean = ${mean_treat:.2f}')\naxes[0].set_title('Treatment Group')\naxes[0].set_xlabel('Donation Amount')\naxes[0].set_ylabel('Number of Donors')\naxes[0].legend()\n\naxes[1].hist(donors_control['amount'], bins=30, color='lightgreen', edgecolor='black')\naxes[1].axvline(mean_control, color='red', linestyle='--', label=f'Mean = ${mean_control:.2f}')\naxes[1].set_title('Control Group')\naxes[1].set_xlabel('Donation Amount')\naxes[1].legend()\n\nplt.suptitle('Distribution of Donation Amounts (Among Donors)', fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n```\n\n\n\n## Simulation Experiment\n\nAs a reminder of how the t-statistic \"works,\" in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\n\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. \n\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.\n\n### Law of Large Numbers\n\n```{python}\n\nnp.random.seed(42)\n\n# Control group: Bernoulli(p=0.018), 100,000 draws\ncontrol_sim = np.random.binomial(n=1, p=0.018, size=100000)\n\n# Treatment group: Bernoulli(p=0.022), 10,000 draws\ntreatment_sim = np.random.binomial(n=1, p=0.022, size=10000)\n\n# diff_vector = treatment_sim - np.random.choice(control_sim, size=10000)\ndiff_vector = treatment_sim - control_sim[:10000]\n\ncumulative_avg = np.cumsum(diff_vector) / np.arange(1, len(diff_vector) + 1)\n\ntrue_diff = 0.022 - 0.018\n\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, label='Cumulative Average of Differences')\nplt.axhline(y=true_diff, color='red', linestyle='--', label=f'True Difference = {true_diff:.3f}')\nplt.title('Law of Large Numbers: Cumulative Avg of Bernoulli Differences (Treatment - Control)')\nplt.xlabel('Number of Simulated Samples')\nplt.ylabel('Cumulative Average Difference')\nplt.legend()\nplt.tight_layout()\nplt.show()\n```\n\nThe plot above shows the **cumulative average difference** between simulated donations in the treatment and control groups over 10,000 trials. Each trial compares a Bernoulli draw from the **treatment distribution** (p = 0.022) to one from the **control distribution** (p = 0.018).\n\nAs expected under the **Law of Large Numbers**, the cumulative average initially fluctuates substantially due to randomness in small samples. However, as the number of simulations increases, the average steadily stabilizes and **converges toward the true difference in means: 0.004**.\n\nBy around 5,000 simulations, the cumulative average remains tightly clustered around the true value, with only minor variation. This illustrates that:\nWith enough independent observations, the sample average of a statistic becomes a reliable estimate of its population value.\n\n\n\n\n### Central Limit Theorem\n\n```{python}\n\nsample_sizes = [50, 200, 500, 1000]\nsimulations = 1000\np_control = 0.018\np_treatment = 0.022\n\ndiff_distributions = {}\n\nnp.random.seed(42)\n\nfor n in sample_sizes:\n    diffs = []\n    for _ in range(simulations):\n        control_draw = np.random.binomial(1, p_control, n)\n        treatment_draw = np.random.binomial(1, p_treatment, n)\n        mean_diff = treatment_draw.mean() - control_draw.mean()\n        diffs.append(mean_diff)\n    diff_distributions[n] = diffs\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    axes[i].hist(diff_distributions[n], bins=30, edgecolor='black', alpha=0.7)\n    axes[i].axvline(0, color='black', linestyle='--', label='Zero')\n    axes[i].set_title(f\"Sample Size = {n}\")\n    axes[i].set_xlabel(\"Mean Difference (Treatment - Control)\")\n    axes[i].axvline(p_treatment - p_control, color='red', linestyle='--', label='True Difference')\n    axes[i].set_ylabel(\"Frequency\")\n    axes[i].legend()\n\nplt.tight_layout()\nplt.show()\n```\n\n\nThe plots above show the sampling distributions of the **difference in means** between the treatment and control groups, based on repeated simulations for different sample sizes: **n = 50, 200, 500, and 1000**.\n\nEach distribution includes:\n- A **red dashed line** for the true population difference (0.004)\n- A **black dashed line** at zero (the null hypothesis of no difference)\n\n#### Interpretation\n\n- **At small sample sizes (n = 50, 200)**, the distributions are **wide and noisy**, and the value zero lies **well within the main body of the distribution**. This means it would be difficult to reject the null hypothesis — the sampling variability is too high.\n  \n- **At larger sample sizes (n = 500, 1000)**, the distribution becomes **narrower and more bell-shaped**, and the value of zero begins to **move toward the tail** of the distribution. This indicates that **larger samples provide more precise estimates**, and it becomes **easier to detect small differences** like the true 0.004 effect.\n\n#### Overall\n\nAs the sample size increases, the sampling distribution becomes tighter and better centered around the true value — a classic demonstration of the **Central Limit Theorem**.\n\nAt larger sample sizes, **zero falls closer to the tail**, suggesting that with sufficient data, we would be more likely to detect a statistically significant treatment effect (even when that effect is small).\n\nThis reinforces the importance of **sample size in hypothesis testing**: small effects can only be detected when the noise is small — which is what large `n` gives us.\n\n\n\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.5","theme":"cosmo","title":"A Replication of Karlan and List (2007)","author":"Alexa Gamble","date":"04/17/2025","callout-appearance":"minimal"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}